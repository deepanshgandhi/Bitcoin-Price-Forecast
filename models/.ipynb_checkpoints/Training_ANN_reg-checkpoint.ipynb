{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.constraints import MaxNorm as maxnorm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "#from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Audio\n",
    "sound_file = 'beep.wav'\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import * \n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T2V(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(T2V, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[-1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.P = self.add_weight(name='P',\n",
    "                                shape=(input_shape[1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.p = self.add_weight(name='p',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        super(T2V, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
    "        \n",
    "        return K.concatenate([sin_trans, original], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pd.read_csv(\"../models/pca_all_reg.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_1</th>\n",
       "      <th>comp_2</th>\n",
       "      <th>comp_3</th>\n",
       "      <th>comp_4</th>\n",
       "      <th>comp_5</th>\n",
       "      <th>comp_6</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074775</td>\n",
       "      <td>-0.058775</td>\n",
       "      <td>-0.016531</td>\n",
       "      <td>-0.026882</td>\n",
       "      <td>-0.018071</td>\n",
       "      <td>0.034708</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103432</td>\n",
       "      <td>-0.097974</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>-0.009610</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.0726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078321</td>\n",
       "      <td>-0.038384</td>\n",
       "      <td>-0.004899</td>\n",
       "      <td>-0.021897</td>\n",
       "      <td>-0.021560</td>\n",
       "      <td>0.029447</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     comp_1    comp_2    comp_3    comp_4    comp_5    comp_6  priceUSD\n",
       "0  0.074775 -0.058775 -0.016531 -0.026882 -0.018071  0.034708    0.0495\n",
       "1  0.103432 -0.097974  0.025112  0.008138 -0.009610  0.003282    0.0726\n",
       "2  0.078321 -0.038384 -0.004899 -0.021897 -0.021560  0.029447    0.0859"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 7)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=dataframe.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataframe.iloc[:,0:length]\n",
    "y = dataframe['priceUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_1</th>\n",
       "      <th>comp_2</th>\n",
       "      <th>comp_3</th>\n",
       "      <th>comp_4</th>\n",
       "      <th>comp_5</th>\n",
       "      <th>comp_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074775</td>\n",
       "      <td>-0.058775</td>\n",
       "      <td>-0.016531</td>\n",
       "      <td>-0.026882</td>\n",
       "      <td>-0.018071</td>\n",
       "      <td>0.034708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103432</td>\n",
       "      <td>-0.097974</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>-0.009610</td>\n",
       "      <td>0.003282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078321</td>\n",
       "      <td>-0.038384</td>\n",
       "      <td>-0.004899</td>\n",
       "      <td>-0.021897</td>\n",
       "      <td>-0.021560</td>\n",
       "      <td>0.029447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     comp_1    comp_2    comp_3    comp_4    comp_5    comp_6\n",
       "0  0.074775 -0.058775 -0.016531 -0.026882 -0.018071  0.034708\n",
       "1  0.103432 -0.097974  0.025112  0.008138 -0.009610  0.003282\n",
       "2  0.078321 -0.038384 -0.004899 -0.021897 -0.021560  0.029447"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0495,  0.0726,  0.0859,  0.0783,  0.0767,  0.0649,  0.0566,\n",
       "        0.0581,  0.053 ,  0.053 ,  0.058 ,  0.0595,  0.0648,  0.0663,\n",
       "        0.0664,  0.0611,  0.0613,  0.06  ,  0.0597,  0.0596,  0.0622,\n",
       "        0.0599,  0.06  ,  0.066 ,  0.069 ,  0.0635,  0.069 ,  0.0655,\n",
       "        0.0663,  0.0661,  0.0643,  0.0678,  0.069 ,  0.0673,  0.0661,\n",
       "        0.066 ,  0.0655,  0.0655,  0.065 ,  0.0656,  0.0644,  0.0645,\n",
       "        0.0646,  0.0644,  0.0648,  0.0621,  0.0625,  0.0622,  0.0609,\n",
       "        0.0618,  0.062 ,  0.0622,  0.0613,  0.0615,  0.0611,  0.0614,\n",
       "        0.0628,  0.0618,  0.0621,  0.062 ,  0.0615,  0.0619,  0.0599,\n",
       "        0.06  ,  0.0618,  0.0621,  0.0629,  0.0623,  0.0622,  0.0621,\n",
       "        0.0621,  0.062 ,  0.0621,  0.0619,  0.062 ,  0.0618,  0.0619,\n",
       "        0.0616,  0.0613,  0.0612,  0.0614,  0.0622,  0.0651,  0.0769,\n",
       "        0.0884,  0.0948,  0.093 ,  0.0945,  0.0985,  0.103 ,  0.103 ,\n",
       "        0.101 ,  0.102 ,  0.103 ,  0.0985,  0.0995,  0.102 ,  0.105 ,\n",
       "        0.107 ,  0.112 ,  0.111 ,  0.142 ,  0.169 ,  0.179 ,  0.185 ,\n",
       "        0.193 ,  0.193 ,  0.194 ,  0.193 ,  0.193 ,  0.214 ,  0.235 ,\n",
       "        0.326 ,  0.405 ,  0.294 ,  0.237 ,  0.225 ,  0.227 ,  0.249 ,\n",
       "        0.282 ,  0.278 ,  0.274 ,  0.246 ,  0.226 ,  0.245 ,  0.274 ,\n",
       "        0.282 ,  0.277 ,  0.28  ,  0.283 ,  0.283 ,  0.281 ,  0.282 ,\n",
       "        0.284 ,  0.277 ,  0.254 ,  0.219 ,  0.219 ,  0.242 ,  0.251 ,\n",
       "        0.23  ,  0.205 ,  0.215 ,  0.213 ,  0.239 ,  0.213 ,  0.202 ,\n",
       "        0.216 ,  0.214 ,  0.22  ,  0.238 ,  0.242 ,  0.244 ,  0.245 ,\n",
       "        0.245 ,  0.244 ,  0.254 ,  0.25  ,  0.247 ,  0.249 ,  0.249 ,\n",
       "        0.249 ,  0.257 ,  0.258 ,  0.272 ,  0.286 ,  0.296 ,  0.3   ,\n",
       "        0.296 ,  0.297 ,  0.293 ,  0.297 ,  0.294 ,  0.299 ,  0.309 ,\n",
       "        0.316 ,  0.323 ,  0.325 ,  0.327 ,  0.323 ,  0.318 ,  0.359 ,\n",
       "        0.393 ,  0.393 ,  0.368 ,  0.331 ,  0.313 ,  0.351 ,  0.405 ,\n",
       "        0.427 ,  0.443 ,  0.431 ,  0.415 ,  0.414 ,  0.415 ,  0.434 ,\n",
       "        0.442 ,  0.462 ,  0.5   ,  0.626 ,  0.713 ,  0.706 ,  0.766 ,\n",
       "        0.88  ,  0.91  ,  0.895 ,  0.904 ,  0.998 ,  1.03  ,  1.025 ,\n",
       "        1.045 ,  1.051 ,  1.055 ,  1.053 ,  1.048 ,  1.043 ,  0.965 ,\n",
       "        0.893 ,  0.899 ,  0.833 ,  0.86  ,  0.905 ,  0.968 ,  0.941 ,\n",
       "        0.935 ,  0.924 ,  0.875 ,  0.89  ,  0.93  ,  0.926 ,  0.906 ,\n",
       "        0.91  ,  0.905 ,  0.878 ,  0.878 ,  0.858 ,  0.899 ,  0.885 ,\n",
       "        0.899 ,  0.896 ,  0.894 ,  0.882 ,  0.863 ,  0.835 ,  0.833 ,\n",
       "        0.771 ,  0.753 ,  0.76  ,  0.784 ,  0.83  ,  0.849 ,  0.875 ,\n",
       "        0.869 ,  0.825 ,  0.809 ,  0.796 ,  0.791 ,  0.787 ,  0.775 ,\n",
       "        0.778 ,  0.78  ,  0.729 ,  0.7   ,  0.744 ,  0.751 ,  0.752 ,\n",
       "        0.74  ,  0.743 ,  0.753 ,  0.819 ,  0.891 ,  0.97  ,  0.995 ,\n",
       "        1.017 ,  1.08  ,  1.15  ,  1.18  ,  1.162 ,  1.176 ,  1.31  ,\n",
       "        1.546 ,  1.716 ,  1.595 ,  1.687 ,  1.841 ,  2.046 ,  2.546 ,\n",
       "        3.215 ,  3.267 ,  3.149 ,  3.305 ,  3.441 ,  3.367 ,  3.393 ,\n",
       "        3.546 ,  3.753 ,  3.835 ,  4.81  ,  5.65  ,  5.895 ,  7.259 ,\n",
       "        7.659 ,  6.995 ,  7.512 ,  7.62  ,  7.036 ,  6.756 ,  6.198 ,\n",
       "        5.96  ,  6.415 ,  6.92  ,  7.285 ,  7.945 ,  8.524 ,  8.6   ,\n",
       "        8.425 ,  8.35  ,  8.624 ,  8.771 ,  9.156 , 10.1   , 12.445 ,\n",
       "       16.501 , 17.833 , 17.625 , 21.092 , 26.8   , 29.415 , 26.434 ,\n",
       "       19.301 , 16.648 , 19.194 , 19.54  , 19.385 , 18.25  , 16.341 ,\n",
       "       16.445 , 17.18  , 17.    , 17.    , 17.    , 17.    , 17.    ,\n",
       "       17.    , 16.98  , 16.6   , 16.85  , 16.9   , 16.473 , 15.736 ,\n",
       "       15.385 , 15.42  , 14.65  , 13.392 , 13.853 , 14.737 , 14.545 ,\n",
       "       14.347 , 14.638 , 14.555 , 14.109 , 13.989 , 13.985 , 13.905 ,\n",
       "       13.765 , 13.44  , 13.32  , 13.66  , 13.787 , 13.665 , 13.653 ,\n",
       "       13.69  , 13.835 , 14.014 , 13.956 , 13.911 , 13.691 , 13.494 ,\n",
       "       13.516 , 13.443 , 13.222 , 12.573 , 10.655 , 10.019 , 10.255 ,\n",
       "        8.145 ,  7.218 ,  7.85  ,  8.895 ,  9.975 ,  9.775 ,  9.462 ,\n",
       "        9.801 , 10.463 , 10.971 , 11.059 , 10.934 , 10.904 , 11.24  ,\n",
       "       11.555 , 11.382 , 11.103 , 10.925 , 10.895 , 10.254 ,  8.918 ,\n",
       "        8.385 ,  8.831 ,  9.02  ,  8.88  ,  8.495 ,  8.205 ,  8.444 ,\n",
       "        8.54  ,  8.321 ,  7.861 ,  7.237 ,  7.025 ,  6.864 ,  5.78  ,\n",
       "        4.897 ,  5.319 ,  6.009 ,  5.925 ,  5.72  ,  5.23  ,  4.83  ,\n",
       "        4.795 ,  4.98  ,  5.331 ,  5.787 ,  5.875 ,  5.536 ,  5.487 ,\n",
       "        5.507 ,  5.375 ,  5.1   ,  4.893 ,  4.844 ,  4.78  ,  4.948 ,\n",
       "        5.1   ,  5.03  ,  5.026 ,  4.992 ,  4.915 ,  4.802 ,  4.51  ,\n",
       "        4.155 ,  4.055 ,  4.1   ,  3.996 ,  4.04  ,  4.103 ,  4.022 ,\n",
       "        3.915 ,  3.7   ,  3.059 ,  2.48  ,  2.345 ,  2.299 ,  2.46  ,\n",
       "        2.874 ,  3.123 ,  2.836 ,  2.647 ,  2.763 ,  2.907 ,  3.115 ,\n",
       "        3.376 ,  3.426 ,  3.262 ,  3.203 ,  3.202 ,  3.202 ,  3.139 ,\n",
       "        3.04  ,  2.965 ,  2.983 ,  3.021 ,  3.011 ,  2.909 ,  2.96  ,\n",
       "        3.049 ,  3.014 ,  2.608 ,  2.274 ,  2.445 ,  2.409 ,  2.158 ,\n",
       "        2.107 ,  2.2   ,  2.246 ,  2.308 ,  2.33  ,  2.379 ,  2.472 ,\n",
       "        2.468 ,  2.475 ,  2.515 ,  2.65  ,  2.859 ,  3.028 ,  3.086 ,\n",
       "        2.957 ,  2.811 ,  2.854 ,  2.955 ,  3.009 ,  2.985 ,  2.975 ,\n",
       "        3.01  ,  3.156 ,  3.193 ,  3.212 ,  3.189 ,  3.17  ,  3.198 ,\n",
       "        3.2   ,  3.187 ,  3.357 ,  3.735 ,  3.905 ,  3.883 ,  3.918 ,\n",
       "        3.943 ,  4.083 ,  4.122 ,  4.046 ,  4.128 ,  4.183 ,  4.207 ,\n",
       "        4.485 ,  4.984 ,  5.239 ,  5.048 ,  5.227 ,  6.261 ,  6.822 ,\n",
       "        6.753 ,  6.95  ,  6.705 ,  6.344 ,  6.675 ,  6.85  ,  6.595 ,\n",
       "        6.585 ,  6.876 ,  6.842 ,  6.134 ,  5.735 ,  6.14  ,  6.421 ,\n",
       "        6.339 ,  6.247 ,  6.333 ,  6.323 ,  6.02  ,  5.57  ,  5.316 ,\n",
       "        5.459 ,  5.503 ,  5.435 ,  5.487 ,  5.805 ,  6.081 ,  6.03  ,\n",
       "        5.917 ,  5.781 ,  5.556 ,  5.586 ,  5.645 ,  5.715 ,  5.871 ,\n",
       "        5.754 ,  5.572 ,  5.387 ,  4.861 ,  4.394 ,  4.29  ,  4.326 ,\n",
       "        4.302 ,  4.304 ,  4.361 ,  4.325 ,  4.349 ,  4.735 ,  5.022 ,\n",
       "        4.901 ,  4.848 ,  4.939 ,  4.909 ,  4.864 ,  4.891 ,  4.813 ,\n",
       "        4.671 ,  4.717 ,  4.902 ,  4.989 ,  4.964 ,  4.934 ,  4.896 ,\n",
       "        4.847 ,  4.872 ,  4.899 ,  5.08  ,  5.331 ,  5.36  ,  5.346 ,\n",
       "        5.28  ,  5.248 ,  4.975 ,  4.755 ,  4.826 ,  4.749 ,  4.711 ,\n",
       "        4.681 ,  4.613 ,  4.585 ,  4.718 ,  4.806 ,  4.785 ,  4.834 ,\n",
       "        4.878 ,  4.85  ,  4.878 ,  4.963 ,  4.93  ,  4.922 ,  4.934 ,\n",
       "        4.819 ,  4.74  ,  4.831 ,  4.854 ,  4.882 ,  4.924 ,  4.916 ,\n",
       "        4.95  ,  4.964 ,  4.951 ,  4.968 ,  5.047 ,  5.128 ,  5.244 ,\n",
       "        5.329 ,  5.232 ,  5.082 ,  5.029 ,  5.116 ,  5.115 ,  5.104 ,\n",
       "        5.04  ,  4.942 ,  4.931 ,  4.975 ,  5.037 ,  5.104 ,  5.088 ,\n",
       "        5.072 ,  5.064 ,  5.055 ,  5.069 ,  5.047 ,  4.955 ,  4.905 ,\n",
       "        4.948 ,  4.94  ,  4.978 ,  5.029 ,  5.063 ,  5.094 ,  5.109 ,\n",
       "        5.112 ,  5.104 ,  5.1   ,  5.099 ,  5.119 ,  5.129 ,  5.132 ,\n",
       "        5.109 ,  5.121 ,  5.133 ,  5.145 ,  5.142 ,  5.158 ,  5.237 ,\n",
       "        5.262 ,  5.227 ,  5.243 ,  5.353 ,  5.45  ,  5.529 ,  5.612 ,\n",
       "        5.596 ,  5.514 ,  5.522 ,  5.648 ,  5.829 ,  5.941 ,  6.227 ,\n",
       "        6.45  ,  6.306 ,  6.255 ,  6.404 ,  6.584 ,  6.675 ,  6.614 ,\n",
       "        6.488 ,  6.389 ,  6.327 ,  6.375 ,  6.553 ,  6.626 ,  6.628 ,\n",
       "        6.67  ,  6.659 ,  6.68  ,  6.605 ,  6.48  ,  6.59  ,  6.659 ,\n",
       "        6.731 ,  6.781 ,  6.907 ,  7.111 ,  7.175 ,  7.467 ,  7.676 ,\n",
       "        7.571 ,  7.582 ,  8.091 ,  8.65  ,  8.955 ,  8.99  ,  8.695 ])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 6)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, train_size=0.8, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(['mixmax',MinMaxScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(['robust',RobustScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=Pipeline(estimators,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing mixmax, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing robust, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('mixmax', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ['robust',\n",
       "                 RobustScaler(copy=True, quantile_range=(25.0, 75.0),\n",
       "                              with_centering=True, with_scaling=True)]],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scale.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "def sequential_model(initializer='normal', activation='relu', neurons=300, NUM_FEATURES=shape):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_shape=(NUM_FEATURES,), kernel_initializer=initializer, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1, activation=activation, kernel_initializer=initializer))\n",
    "    model.add(T2V(neurons))\n",
    "    model.add(LSTM(neurons, activation=activation))\n",
    "    # Compile model\n",
    "    adam=keras.optimizers.Adam(lr=lr_schedule(0), amsgrad=True)\n",
    "    #sgd=keras.optimizers.SGD(learning_rate=0.08, momentum=0.9, nesterov=False)\n",
    "    model.compile(loss='logcosh', optimizer=adam, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('ANN_reg_seven_new.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10,verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=KerasRegressor(build_fn=sequential_model, batch_size=64, epochs=100,verbose=1, shuffle=True,\n",
    "                         validation_split=0.1,validation_freq=1,\n",
    "                        use_multiprocessing=True) #callbacks=[mcp_save,earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Train on 529 samples, validate on 59 samples\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 7s 13ms/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 0s 189us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 0s 177us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 0s 225us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 0s 195us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 0s 176us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 0s 188us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 0s 226us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 0s 173us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 0s 162us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 0s 161us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 0s 146us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 0s 159us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 0s 163us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 0s 149us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 0s 182us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 0s 160us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 0s 172us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 0s 178us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 0s 181us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 0s 183us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 0s 151us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 0s 151us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 0s 158us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 0s 186us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 0s 221us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 0s 178us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 0s 176us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 0s 177us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 0s 159us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 0s 176us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 0s 164us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 0s 161us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 0s 146us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 0s 148us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 0s 148us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 0s 148us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 0s 142us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 0s 144us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 0s 158us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 0s 150us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 0s 162us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 0s 175us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 0s 140us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 0s 179us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 0s 167us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 0s 172us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 0s 149us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "529/529 [==============================] - 0s 135us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 0s 131us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 0s 151us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 0s 162us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 0s 151us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 0s 145us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 0s 145us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 0s 135us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 0s 146us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 0s 145us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 0s 139us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 0s 156us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 0s 136us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 0s 145us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 0s 147us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 0s 159us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 0s 147us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 0s 149us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 0s 162us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 0s 177us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 0s 167us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 0s 187us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 0s 203us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 0s 157us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 0s 135us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 0s 144us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 0s 135us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 0s 137us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 0s 147us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 0s 152us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 0s 143us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 0s 149us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 0s 128us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 0s 146us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 0s 155us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 0s 147us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 0s 181us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 0s 177us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 0s 167us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 0s 169us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 0s 148us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 0s 169us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 0s 164us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 0s 179us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 0s 166us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 0s 196us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 0s 160us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 0s 174us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/529 [==============================] - 0s 140us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 0s 164us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 0s 183us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 0s 167us/sample - loss: 3.7218 - mean_absolute_error: 4.2412 - val_loss: 4.2345 - val_mean_absolute_error: 4.7704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f41113da990>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "regressor.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train_pred=regressor.predict(X_train)\n",
    "#X_train[0:]\n",
    "#list(zip(*X_train))[0]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8613751452930594"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred) #training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 0s 64us/sample\n"
     ]
    }
   ],
   "source": [
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.365</td>\n",
       "      <td>102.790520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383.996</td>\n",
       "      <td>2218.788818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312.341</td>\n",
       "      <td>1558.035034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>838.570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>604.807</td>\n",
       "      <td>2948.683838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>120.003</td>\n",
       "      <td>1277.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>613.783</td>\n",
       "      <td>277.415253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>617.300</td>\n",
       "      <td>2845.676514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>222.448</td>\n",
       "      <td>2187.849365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>328.083</td>\n",
       "      <td>1302.353394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_test       y_pred\n",
       "0    283.365   102.790520\n",
       "1    383.996  2218.788818\n",
       "2    312.341  1558.035034\n",
       "3    838.570     0.000000\n",
       "4    604.807  2948.683838\n",
       "..       ...          ...\n",
       "142  120.003  1277.599976\n",
       "143  613.783   277.415253\n",
       "144  617.300  2845.676514\n",
       "145  222.448  2187.849365\n",
       "146  328.083  1302.353394\n",
       "\n",
       "[147 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(y_test,y_pred),columns=['y_test','y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-404.9971106140285"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2=r2_score(y_test,y_pred) #testing score/ r^2\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2797.461182416228"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae=mean_absolute_error(y_test,y_pred) #mae\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4686.802277097698"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred)) #rmse\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mape=mean_absolute_percentage_error(y_test,y_pred) #mape\n",
    "#mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>R^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2797.46</td>\n",
       "      <td>4686.8</td>\n",
       "      <td>-404.997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1        2\n",
       "0      MAE    RMSE      R^2\n",
       "1  2797.46  4686.8 -404.997"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(['MAE','RMSE','R^2'],[mae,rmse,r2])).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.model.save('ANN_reg_seven_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 300)               2100      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 183,001\n",
      "Trainable params: 183,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4020, 742)\n",
      "(3618, 30, 1) (3618, 1)\n",
      "(372, 30, 1) (372, 1)\n",
      "Train on 2894 samples, validate on 724 samples\n",
      "Epoch 1/5000\n",
      "2894/2894 [==============================] - 22s 8ms/sample - loss: 724785.1575 - val_loss: 4957954.9475\n",
      "Epoch 2/5000\n",
      "2894/2894 [==============================] - 4s 1ms/sample - loss: 2395394.9265 - val_loss: 11575635.3591\n",
      "Epoch 3/5000\n",
      "2894/2894 [==============================] - 4s 1ms/sample - loss: 30386432.5219 - val_loss: 159970153.2376\n",
      "Epoch 4/5000\n",
      "2894/2894 [==============================] - 4s 1ms/sample - loss: 306635104.9406 - val_loss: 117572738.8950\n",
      "Epoch 5/5000\n",
      "2894/2894 [==============================] - 5s 2ms/sample - loss: 6332835.8318 - val_loss: 37330599.6685\n",
      "Epoch 6/5000\n",
      "2894/2894 [==============================] - 5s 2ms/sample - loss: 12706046.0047 - val_loss: 48017968.1768\n",
      "Epoch 7/5000\n",
      "2894/2894 [==============================] - 4s 1ms/sample - loss: 8295580.3297 - val_loss: 39572374.4862\n",
      "Epoch 8/5000\n",
      "1536/2894 [==============>...............] - ETA: 1s - loss: 78844.1681"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-e3cb9498eff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;31m# pred_t2v = kgs_t2v.best_model.predict(X_test).ravel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m# pred_t2v = model.predict(X_test).ravel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### DEFINE T2V LAYER ###\n",
    "\n",
    "\n",
    "class T2V(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(T2V, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[-1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.P = self.add_weight(name='P',\n",
    "                                shape=(input_shape[1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.p = self.add_weight(name='p',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        super(T2V, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
    "        \n",
    "        return K.concatenate([sin_trans, original], -1)\n",
    "    \n",
    "### CREATE GENERATOR FOR LSTM AND T2V ###\n",
    "\n",
    "sequence_length = 30 # orig: 24 .  note, 24*7 = 168\n",
    "\n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \n",
    "    data_matrix = id_df[seq_cols].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    \n",
    "    data_matrix = id_df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    \n",
    "    return data_matrix[seq_length:num_elements, :]\n",
    "### DEFINE MODEL STRUCTURES ###\n",
    "\n",
    "def set_seed_TF2(seed):\n",
    "    \n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    \n",
    "def T2V_NN(param, dim):\n",
    "    \n",
    "    inp = Input(shape=(dim,1))\n",
    "    x = T2V(param['t2v_dim'])(inp)\n",
    "    x = LSTM(param['unit'], activation=param['act'])(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1)(x)\n",
    "    \n",
    "    m = Model(inp, x)\n",
    "    m.compile(loss='mse', optimizer=Adam(lr=param['lr']))\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "def NN(param, dim):\n",
    "    \n",
    "    inp = Input(shape=(dim,1))\n",
    "    x = LSTM(param['unit'], activation=param['act'])(inp)\n",
    "    x = Dense(1)(x)\n",
    "    \n",
    "    m = Model(inp, x)\n",
    "    m.compile(loss='mse', optimizer=Adam(lr=param['lr']))\n",
    "    \n",
    "    return m\n",
    "### PREPARE DATA TO FEED MODELS ###\n",
    "df[\"Data\"] = df[\"Date\"].dt.date\n",
    "df[\"Ora solare\"] = df[\"Date\"].dt.hour\n",
    "df.drop([\"datetime\"],axis=1,inplace=True, errors=\"ignore\")\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "X, Y = [], []\n",
    "for sequence in gen_sequence(df, sequence_length, ['priceUSD']):\n",
    "    X.append(sequence)\n",
    "    \n",
    "for sequence in gen_labels(df, sequence_length, ['priceUSD']):\n",
    "    Y.append(sequence)\n",
    "    \n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "### TRAIN TEST SPLIT ###\n",
    "\n",
    "train_dim = int(0.9*len(df))\n",
    "X_train, X_test = X[:train_dim], X[train_dim:]\n",
    "y_train, y_test = Y[:train_dim], Y[train_dim:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "### DEFINE PARAM GRID FOR HYPERPARM OPTIMIZATION ###\n",
    "\n",
    "base_param = {\n",
    "    'unit': 64,\n",
    "    't2v_dim': 64,\n",
    "    'lr': 2e-3, \n",
    "    'act': 'relu', \n",
    "    'epochs': 100, # 200,\n",
    "    'batch_size': 256\n",
    "}\n",
    "\n",
    "model = NN(param=base_param, dim=sequence_length)\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=False, epochs=5000)\n",
    "# pred_t2v = kgs_t2v.best_model.predict(X_test).ravel()\n",
    "# pred_t2v = model.predict(X_test).ravel()\n",
    "# print(\"MAE\")\n",
    "# mean_absolute_error(y_test.ravel(), pred_t2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
