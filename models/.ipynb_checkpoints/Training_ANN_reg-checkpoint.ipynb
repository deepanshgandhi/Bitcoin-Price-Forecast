{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.constraints import MaxNorm as maxnorm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "#from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Audio\n",
    "#sound_file = 'beep.wav'\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import * \n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T2V(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(T2V, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[-1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.P = self.add_weight(name='P',\n",
    "                                shape=(input_shape[1], self.output_dim),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.p = self.add_weight(name='p',\n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        super(T2V, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
    "        \n",
    "        return K.concatenate([sin_trans, original], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "#dataframe = pd.read_csv(\"../data/bitcoin_ticker.csv\", sep=',')\n",
    "dataframe = pd.read_csv(\"../data/new/features_regression_boruta_plus_rf.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reg_seven = [\"difficulty30rsi\", \"difficulty90var\",\"fee_to_reward90rsiUSD\",\"hashrate30var\",\"median_transaction_fee7rocUSD\",\"mining_profitability\",\"price30smaUSD\",\"price3wmaUSD\",\"price7wmaUSD\",\"sentinusd90emaUSD\",\"size90trx\",\"top100cap\",\"transactionvalueUSD\",\"priceUSD\"]\n",
    "#dataframe = dataframe[reg_seven]\n",
    "dataframe.head(3)\n",
    "#dataframe = dataframe.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_train_pred=regressor.predict(X_train)\n",
    "# # #X_train[0:]\n",
    "# # #list(zip(*X_train))[0]\n",
    "# # y_train.shape\n",
    "# #dataframe.describe()\n",
    "\n",
    "length=dataframe.shape[1]-1\n",
    "df = dataframe\n",
    "\n",
    "for i in dataframe.columns:\n",
    "    try:\n",
    "        dataframe[i] = np.where(dataframe[i] > df[i].quantile(0.75), df[i].quantile(0.50), df[i])\n",
    "        dataframe[i] = np.where(dataframe[i] < df[i].quantile(0.25), df[i].quantile(0.50), df[i])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "# z = np.abs(stats.zscore(dataframe))\n",
    "\n",
    "# Q1 = dataframe.quantile(0.25)\n",
    "# Q3 = dataframe.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "\n",
    "\n",
    "# df_o = dataframe[(z < 3).all(axis=1)]\n",
    "# df_out = df_o[~((df_o < (Q1 - 1.5 * IQR)) |(df_o > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "# dataframe = df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{86.59100000000002,\n",
       " 87.454,\n",
       " 87.10799999999998,\n",
       " 89.05,\n",
       " 89.28299999999999,\n",
       " 91.849,\n",
       " 92.446,\n",
       " 86.48299999999998,\n",
       " 94.715,\n",
       " 94.679,\n",
       " 87.875,\n",
       " 97.247,\n",
       " 98.435,\n",
       " 98.478,\n",
       " 100.25,\n",
       " 100.355,\n",
       " 102.694,\n",
       " 103.663,\n",
       " 103.671,\n",
       " 104.575,\n",
       " 105.04,\n",
       " 105.104,\n",
       " 105.826,\n",
       " 105.11,\n",
       " 105.799,\n",
       " 106.7,\n",
       " 106.072,\n",
       " 106.115,\n",
       " 107.749,\n",
       " 107.292,\n",
       " 107.66,\n",
       " 108.42,\n",
       " 109.595,\n",
       " 110.375,\n",
       " 120.405,\n",
       " 112.503,\n",
       " 119.368,\n",
       " 123.693,\n",
       " 115.0,\n",
       " 116.686,\n",
       " 126.316,\n",
       " 118.696,\n",
       " 120.096,\n",
       " 120.003,\n",
       " 124.135,\n",
       " 124.605,\n",
       " 125.725,\n",
       " 126.909,\n",
       " 126.424,\n",
       " 128.664,\n",
       " 128.75,\n",
       " 130.56,\n",
       " 132.945,\n",
       " 134.114,\n",
       " 134.8,\n",
       " 134.465,\n",
       " 139.74,\n",
       " 134.739,\n",
       " 136.214,\n",
       " 142.08,\n",
       " 138.704,\n",
       " 143.72299999999996,\n",
       " 153.886,\n",
       " 157.329,\n",
       " 163.561,\n",
       " 164.81,\n",
       " 169.46900000000005,\n",
       " 172.97,\n",
       " 178.5,\n",
       " 178.428,\n",
       " 180.316,\n",
       " 185.605,\n",
       " 188.042,\n",
       " 191.426,\n",
       " 193.134,\n",
       " 195.397,\n",
       " 195.57,\n",
       " 195.73,\n",
       " 197.87,\n",
       " 199.6,\n",
       " 197.577,\n",
       " 200.604,\n",
       " 202.56,\n",
       " 205.937,\n",
       " 205.929,\n",
       " 210.64,\n",
       " 211.756,\n",
       " 211.824,\n",
       " 213.806,\n",
       " 214.636,\n",
       " 213.673,\n",
       " 218.482,\n",
       " 219.936,\n",
       " 220.946,\n",
       " 218.176,\n",
       " 222.448,\n",
       " 220.585,\n",
       " 224.9,\n",
       " 225.308,\n",
       " 226.795,\n",
       " 227.909,\n",
       " 225.863,\n",
       " 229.752,\n",
       " 226.535,\n",
       " 231.403,\n",
       " 232.311,\n",
       " 232.4,\n",
       " 232.471,\n",
       " 231.691,\n",
       " 236.83,\n",
       " 237.937,\n",
       " 238.794,\n",
       " 237.146,\n",
       " 234.532,\n",
       " 239.441,\n",
       " 238.71,\n",
       " 243.629,\n",
       " 239.529,\n",
       " 237.832,\n",
       " 242.991,\n",
       " 244.115,\n",
       " 241.202,\n",
       " 246.158,\n",
       " 248.284,\n",
       " 248.51,\n",
       " 250.235,\n",
       " 250.348,\n",
       " 252.788,\n",
       " 252.709,\n",
       " 251.478,\n",
       " 248.965,\n",
       " 256.186,\n",
       " 257.124,\n",
       " 251.271,\n",
       " 259.368,\n",
       " 260.716,\n",
       " 261.244,\n",
       " 262.486,\n",
       " 261.797,\n",
       " 257.67,\n",
       " 262.642,\n",
       " 267.213,\n",
       " 260.055,\n",
       " 269.036,\n",
       " 270.497,\n",
       " 264.51,\n",
       " 272.076,\n",
       " 273.146,\n",
       " 274.025,\n",
       " 274.82,\n",
       " 276.10400000000004,\n",
       " 275.36400000000003,\n",
       " 278.934,\n",
       " 272.846,\n",
       " 280.21,\n",
       " 281.323,\n",
       " 283.7940000000001,\n",
       " 275.22700000000003,\n",
       " 281.962,\n",
       " 283.365,\n",
       " 287.178,\n",
       " 287.5420000000001,\n",
       " 283.896,\n",
       " 290.818,\n",
       " 291.892,\n",
       " 291.01,\n",
       " 293.828,\n",
       " 293.97,\n",
       " 294.297,\n",
       " 288.825,\n",
       " 291.386,\n",
       " 298.115,\n",
       " 293.763,\n",
       " 291.318,\n",
       " 294.087,\n",
       " 301.252,\n",
       " 303.591,\n",
       " 304.274,\n",
       " 309.563,\n",
       " 311.944,\n",
       " 312.6620000000001,\n",
       " 312.341,\n",
       " 314.01,\n",
       " 315.801,\n",
       " 315.441,\n",
       " 314.822,\n",
       " 318.737,\n",
       " 319.032,\n",
       " 312.724,\n",
       " 315.626,\n",
       " 322.456,\n",
       " 323.149,\n",
       " 324.34,\n",
       " 325.84,\n",
       " 324.713,\n",
       " 327.819,\n",
       " 328.3130000000001,\n",
       " 329.102,\n",
       " 323.943,\n",
       " 328.083,\n",
       " 332.744,\n",
       " 329.1880000000001,\n",
       " 334.983,\n",
       " 335.1690000000001,\n",
       " 336.63,\n",
       " 337.866,\n",
       " 336.991,\n",
       " 339.094,\n",
       " 335.73800000000006,\n",
       " 341.339,\n",
       " 342.284,\n",
       " 343.176,\n",
       " 344.899,\n",
       " 345.8780000000001,\n",
       " 344.945,\n",
       " 342.4840000000001,\n",
       " 347.5,\n",
       " 349.089,\n",
       " 349.881,\n",
       " 351.284,\n",
       " 352.7940000000001,\n",
       " 352.906,\n",
       " 351.592,\n",
       " 355.716,\n",
       " 356.53,\n",
       " 352.726,\n",
       " 358.505,\n",
       " 359.3880000000001,\n",
       " 351.872,\n",
       " 354.843,\n",
       " 362.28,\n",
       " 362.544,\n",
       " 364.531,\n",
       " 365.791,\n",
       " 366.689,\n",
       " 367.304,\n",
       " 367.289,\n",
       " 369.033,\n",
       " 365.837,\n",
       " 371.775,\n",
       " 370.752,\n",
       " 365.764,\n",
       " 374.924,\n",
       " 367.19,\n",
       " 368.947,\n",
       " 377.415,\n",
       " 377.698,\n",
       " 379.119,\n",
       " 378.689,\n",
       " 379.451,\n",
       " 382.291,\n",
       " 383.996,\n",
       " 384.11800000000005,\n",
       " 384.702,\n",
       " 386.265,\n",
       " 382.802,\n",
       " 388.404,\n",
       " 386.82,\n",
       " 390.912,\n",
       " 382.2,\n",
       " 383.251,\n",
       " 393.788,\n",
       " 394.94,\n",
       " 393.696,\n",
       " 393.935,\n",
       " 397.306,\n",
       " 397.121,\n",
       " 392.939,\n",
       " 400.994,\n",
       " 401.12,\n",
       " 400.275,\n",
       " 403.328,\n",
       " 404.503,\n",
       " 405.935,\n",
       " 401.439,\n",
       " 407.531,\n",
       " 407.703,\n",
       " 409.784,\n",
       " 409.752,\n",
       " 410.271,\n",
       " 411.941,\n",
       " 412.669,\n",
       " 412.764,\n",
       " 412.853,\n",
       " 413.802,\n",
       " 413.346,\n",
       " 413.077,\n",
       " 414.027,\n",
       " 414.983,\n",
       " 415.778,\n",
       " 415.443,\n",
       " 415.288,\n",
       " 415.821,\n",
       " 416.991,\n",
       " 417.945,\n",
       " 418.234,\n",
       " 428.98800000000006,\n",
       " 429.73800000000006,\n",
       " 421.19,\n",
       " 423.3,\n",
       " 423.456,\n",
       " 424.11300000000006,\n",
       " 425.31,\n",
       " 435.76,\n",
       " 436.765,\n",
       " 436.562,\n",
       " 437.468,\n",
       " 437.065,\n",
       " 438.518,\n",
       " 438.567,\n",
       " 439.047,\n",
       " 440.857,\n",
       " 441.538,\n",
       " 441.485,\n",
       " 441.529,\n",
       " 441.268,\n",
       " 442.068,\n",
       " 441.669,\n",
       " 443.354,\n",
       " 443.871,\n",
       " 443.215,\n",
       " 453.641,\n",
       " 453.949,\n",
       " 446.281,\n",
       " 447.946,\n",
       " 448.574,\n",
       " 449.287,\n",
       " 450.932,\n",
       " 451.812,\n",
       " 453.251,\n",
       " 454.031,\n",
       " 456.496,\n",
       " 457.005,\n",
       " 459.325,\n",
       " 464.777,\n",
       " 467.61300000000006,\n",
       " 465.278,\n",
       " 466.322,\n",
       " 466.454,\n",
       " 469.42800000000005,\n",
       " 470.073,\n",
       " 472.322,\n",
       " 474.915,\n",
       " 475.58,\n",
       " 475.441,\n",
       " 476.655,\n",
       " 477.176,\n",
       " 475.398,\n",
       " 476.297,\n",
       " 481.297,\n",
       " 481.482,\n",
       " 481.745,\n",
       " 482.398,\n",
       " 484.581,\n",
       " 486.543,\n",
       " 95.875,\n",
       " 488.836,\n",
       " 96.0,\n",
       " 96.293,\n",
       " 491.137,\n",
       " 96.952,\n",
       " 96.543,\n",
       " 487.666,\n",
       " 490.961,\n",
       " 491.704,\n",
       " 98.0,\n",
       " 494.668,\n",
       " 492.31,\n",
       " 498.97,\n",
       " 499.8,\n",
       " 502.862,\n",
       " 502.665,\n",
       " 499.324,\n",
       " 501.271,\n",
       " 506.639,\n",
       " 502.664,\n",
       " 501.845,\n",
       " 100.846,\n",
       " 505.461,\n",
       " 506.064,\n",
       " 504.405,\n",
       " 101.101,\n",
       " 509.156,\n",
       " 513.078,\n",
       " 507.703,\n",
       " 514.911,\n",
       " 509.791,\n",
       " 517.354,\n",
       " 518.99,\n",
       " 519.347,\n",
       " 521.423,\n",
       " 522.366,\n",
       " 529.149,\n",
       " 532.201,\n",
       " 533.135,\n",
       " 534.594,\n",
       " 535.4159999999998,\n",
       " 107.0,\n",
       " 543.197,\n",
       " 547.519,\n",
       " 550.5,\n",
       " 551.058,\n",
       " 551.979,\n",
       " 552.184,\n",
       " 554.5219999999998,\n",
       " 111.875,\n",
       " 560.0830000000002,\n",
       " 561.09,\n",
       " 559.931,\n",
       " 563.3480000000002,\n",
       " 563.641,\n",
       " 565.081,\n",
       " 564.372,\n",
       " 567.6569999999998,\n",
       " 565.303,\n",
       " 113.005,\n",
       " 570.345,\n",
       " 571.987,\n",
       " 572.999,\n",
       " 573.875,\n",
       " 574.509,\n",
       " 574.95,\n",
       " 573.388,\n",
       " 577.854,\n",
       " 578.305,\n",
       " 579.582,\n",
       " 580.375,\n",
       " 580.2769999999998,\n",
       " 582.231,\n",
       " 574.994,\n",
       " 584.169,\n",
       " 576.2719999999998,\n",
       " 577.7080000000002,\n",
       " 587.908,\n",
       " 579.599,\n",
       " 589.485,\n",
       " 590.957,\n",
       " 589.476,\n",
       " 583.871,\n",
       " 593.201,\n",
       " 585.681,\n",
       " 595.946,\n",
       " 596.009,\n",
       " 597.613,\n",
       " 596.048,\n",
       " 599.545,\n",
       " 591.067,\n",
       " 601.887,\n",
       " 594.664,\n",
       " 603.129,\n",
       " 604.807,\n",
       " 596.985,\n",
       " 598.9,\n",
       " 607.673,\n",
       " 600.002,\n",
       " 607.944,\n",
       " 604.2080000000002,\n",
       " 605.63,\n",
       " 606.793,\n",
       " 613.511,\n",
       " 614.2909999999998,\n",
       " 615.988,\n",
       " 613.783,\n",
       " 616.557,\n",
       " 617.3,\n",
       " 123.947,\n",
       " 123.832,\n",
       " 617.851,\n",
       " 622.409,\n",
       " 618.523,\n",
       " 124.149,\n",
       " 618.92,\n",
       " 618.566,\n",
       " 619.677,\n",
       " 628.232,\n",
       " 620.059,\n",
       " 630.288,\n",
       " 630.3009999999998,\n",
       " 625.927,\n",
       " 633.999,\n",
       " 634.818,\n",
       " 634.091,\n",
       " 126.822,\n",
       " 637.878,\n",
       " 636.984,\n",
       " 127.245,\n",
       " 638.79,\n",
       " 641.523,\n",
       " 642.185,\n",
       " 642.504,\n",
       " 644.487,\n",
       " 636.5790000000002,\n",
       " 643.645,\n",
       " 645.747,\n",
       " 648.195,\n",
       " 649.274,\n",
       " 650.085,\n",
       " 651.2719999999998,\n",
       " 652.469,\n",
       " 650.778,\n",
       " 652.884,\n",
       " 654.137,\n",
       " 650.7669999999998,\n",
       " 649.939,\n",
       " 658.89,\n",
       " 659.682,\n",
       " 659.574,\n",
       " 661.433,\n",
       " 662.002,\n",
       " 663.529,\n",
       " 661.3530000000002,\n",
       " 664.422,\n",
       " 659.5210000000002,\n",
       " 660.703,\n",
       " 662.495,\n",
       " 669.2869999999998,\n",
       " 670.7280000000002,\n",
       " 670.3939999999999,\n",
       " 670.711,\n",
       " 673.0010000000002,\n",
       " 674.2510000000002,\n",
       " 675.1160000000001,\n",
       " 676.2289999999998,\n",
       " 677.6060000000001,\n",
       " 673.449,\n",
       " 675.1339999999999,\n",
       " 681.946,\n",
       " 682.671,\n",
       " 683.826,\n",
       " 682.275,\n",
       " 685.852,\n",
       " 686.885,\n",
       " 685.3560000000001,\n",
       " 696.6610000000002,\n",
       " 696.1360000000002,\n",
       " 698.831,\n",
       " 698.7919999999998,\n",
       " 701.676,\n",
       " 702.545,\n",
       " 702.682,\n",
       " 704.7860000000002,\n",
       " 705.335,\n",
       " 703.872,\n",
       " 705.7610000000002,\n",
       " 708.671,\n",
       " 708.5419999999998,\n",
       " 709.94,\n",
       " 714.235,\n",
       " 714.44,\n",
       " 720.715,\n",
       " 720.1210000000002,\n",
       " 721.6519999999998,\n",
       " 723.096,\n",
       " 724.827,\n",
       " 724.0989999999998,\n",
       " 724.306,\n",
       " 727.9010000000002,\n",
       " 729.7589999999999,\n",
       " 730.449,\n",
       " 732.6310000000002,\n",
       " 733.548,\n",
       " 734.99,\n",
       " 734.423,\n",
       " 734.9830000000002,\n",
       " 734.7860000000002,\n",
       " 738.6389999999999,\n",
       " 738.125,\n",
       " 740.325,\n",
       " 741.868,\n",
       " 742.568,\n",
       " 742.5219999999998,\n",
       " 744.823,\n",
       " 742.446,\n",
       " 738.4910000000001,\n",
       " 747.682,\n",
       " 748.164,\n",
       " 747.6460000000002,\n",
       " 747.59,\n",
       " 753.055,\n",
       " 753.295,\n",
       " 754.931,\n",
       " 756.6139999999998,\n",
       " 755.702,\n",
       " 760.7189999999998,\n",
       " 760.565,\n",
       " 764.4830000000002,\n",
       " 764.0110000000002,\n",
       " 766.6519999999998,\n",
       " 767.6569999999998,\n",
       " 768.4939999999998,\n",
       " 767.304,\n",
       " 771.1439999999999,\n",
       " 771.9910000000001,\n",
       " 774.416,\n",
       " 774.3710000000002,\n",
       " 776.7139999999998,\n",
       " 777.648,\n",
       " 776.7080000000002,\n",
       " 779.773,\n",
       " 779.035,\n",
       " 781.2919999999998,\n",
       " 786.632,\n",
       " 787.6619999999998,\n",
       " 789.416,\n",
       " 789.909,\n",
       " 793.6289999999998,\n",
       " 796.6439999999999,\n",
       " 798.2130000000002,\n",
       " 800.337,\n",
       " 805.197,\n",
       " 808.1569999999998,\n",
       " 811.0210000000002,\n",
       " 812.648,\n",
       " 816.934,\n",
       " 817.692,\n",
       " 816.1419999999998,\n",
       " 822.71,\n",
       " 824.5419999999998,\n",
       " 825.551,\n",
       " 825.581,\n",
       " 825.8610000000001,\n",
       " 829.446,\n",
       " 830.298,\n",
       " 834.51,\n",
       " 834.69,\n",
       " 836.905,\n",
       " 837.415,\n",
       " 837.8969999999998,\n",
       " 838.57,\n",
       " 835.689,\n",
       " 842.293,\n",
       " 843.3580000000002,\n",
       " 844.33,\n",
       " 846.22,\n",
       " 848.331,\n",
       " 849.84,\n",
       " 852.448,\n",
       " 853.6210000000002,\n",
       " 854.784,\n",
       " 854.1080000000002,\n",
       " 856.334,\n",
       " 857.806,\n",
       " 852.382,\n",
       " 859.05,\n",
       " 861.16,\n",
       " 863.039,\n",
       " 865.388,\n",
       " 870.1339999999999,\n",
       " 871.821,\n",
       " 873.1619999999998,\n",
       " 877.685,\n",
       " 882.9860000000001,\n",
       " 886.057,\n",
       " 887.697,\n",
       " 890.7280000000002,\n",
       " 891.298,\n",
       " 890.2360000000001,\n",
       " 893.878,\n",
       " 894.707,\n",
       " 892.331,\n",
       " 896.85,\n",
       " 897.765,\n",
       " 894.1560000000002,\n",
       " 899.4760000000001,\n",
       " 899.0889999999998,\n",
       " 903.996,\n",
       " 906.179,\n",
       " 908.784,\n",
       " 911.027,\n",
       " 914.81,\n",
       " 915.571,\n",
       " 916.265,\n",
       " 917.898,\n",
       " 916.819,\n",
       " 914.851,\n",
       " 920.879,\n",
       " 918.084,\n",
       " 914.645,\n",
       " 916.865,\n",
       " 915.551,\n",
       " 927.984,\n",
       " 934.539,\n",
       " 934.795,\n",
       " 937.573,\n",
       " 950.293,\n",
       " 950.955,\n",
       " 952.778,\n",
       " 961.717,\n",
       " 965.624,\n",
       " 969.061,\n",
       " 970.988,\n",
       " 973.244,\n",
       " 973.897,\n",
       " 981.667,\n",
       " 984.654,\n",
       " 989.036,\n",
       " 991.025,\n",
       " 994.654,\n",
       " 997.754,\n",
       " 999.914,\n",
       " 1003.0,\n",
       " 1006.0,\n",
       " 1009.0,\n",
       " 1010.0,\n",
       " 1014.0,\n",
       " 1016.0,\n",
       " 1017.0,\n",
       " 1020.0,\n",
       " 1023.0,\n",
       " 1036.0,\n",
       " 1037.0,\n",
       " 1038.0,\n",
       " 1039.0,\n",
       " 1043.0,\n",
       " 1045.0,\n",
       " 1049.0,\n",
       " 1052.0,\n",
       " 1056.0,\n",
       " 1057.0,\n",
       " 1062.0,\n",
       " 1075.0,\n",
       " 1083.0,\n",
       " 1089.0,\n",
       " 1090.0,\n",
       " 1095.0,\n",
       " 221.019,\n",
       " 1114.0,\n",
       " 224.221,\n",
       " 1128.0,\n",
       " 1131.0,\n",
       " 1132.0,\n",
       " 225.106,\n",
       " 225.462,\n",
       " 1140.0,\n",
       " 1142.0,\n",
       " 228.015,\n",
       " 228.197,\n",
       " 229.659,\n",
       " 229.058,\n",
       " 230.404,\n",
       " 230.832,\n",
       " 1160.0,\n",
       " 231.562,\n",
       " 1163.0,\n",
       " 1164.0,\n",
       " 232.298,\n",
       " 1168.0,\n",
       " 233.452,\n",
       " 233.043,\n",
       " 233.409,\n",
       " 1175.0,\n",
       " 234.356,\n",
       " 234.385,\n",
       " 234.61900000000003,\n",
       " 1178.0,\n",
       " 1181.0,\n",
       " 235.894,\n",
       " 1185.0,\n",
       " 236.899,\n",
       " 236.11900000000003,\n",
       " 236.365,\n",
       " 236.928,\n",
       " 236.889,\n",
       " 237.015,\n",
       " 237.726,\n",
       " 237.125,\n",
       " 1190.0,\n",
       " 1196.0,\n",
       " 238.067,\n",
       " 238.539,\n",
       " 1195.0,\n",
       " 1194.0,\n",
       " 1202.0,\n",
       " 1203.0,\n",
       " 240.039,\n",
       " 240.462,\n",
       " 1208.0,\n",
       " 241.37,\n",
       " 1213.0,\n",
       " 1217.0,\n",
       " 242.731,\n",
       " 1218.0,\n",
       " 243.39,\n",
       " 243.394,\n",
       " 1229.0,\n",
       " 245.298,\n",
       " 1233.0,\n",
       " 1237.0,\n",
       " 246.389,\n",
       " 1239.0,\n",
       " 247.452,\n",
       " 247.404,\n",
       " 248.466,\n",
       " 1248.0,\n",
       " 1252.0,\n",
       " 249.74,\n",
       " 1256.0,\n",
       " 1257.0,\n",
       " 1261.0,\n",
       " 251.284,\n",
       " 1269.0,\n",
       " 1270.0,\n",
       " 1271.0,\n",
       " 1273.0,\n",
       " 256.101,\n",
       " 1293.0,\n",
       " 257.741,\n",
       " 257.85400000000004,\n",
       " 1318.0,\n",
       " 263.326,\n",
       " 263.775,\n",
       " 1326.0,\n",
       " 264.053,\n",
       " 264.837,\n",
       " 264.722,\n",
       " 1335.0,\n",
       " 1337.0,\n",
       " 266.726,\n",
       " 267.655,\n",
       " 267.668,\n",
       " 268.562,\n",
       " 268.111,\n",
       " 269.981,\n",
       " 269.135,\n",
       " 271.908,\n",
       " 272.54200000000003,\n",
       " 276.116,\n",
       " 276.61,\n",
       " 1390.0,\n",
       " 277.177,\n",
       " 277.466,\n",
       " 278.091,\n",
       " 279.10900000000004,\n",
       " 279.731,\n",
       " 280.98,\n",
       " 280.317,\n",
       " 282.591,\n",
       " 283.586,\n",
       " 284.668,\n",
       " 284.408,\n",
       " 1437.0,\n",
       " 287.751,\n",
       " 289.505,\n",
       " 290.788,\n",
       " 290.8040000000001,\n",
       " 1462.0,\n",
       " 292.005,\n",
       " 89.193,\n",
       " 91.241,\n",
       " 94.938,\n",
       " 97.39,\n",
       " 97.996,\n",
       " 1517.0,\n",
       " 1530.0,\n",
       " 1534.0,\n",
       " 1541.0,\n",
       " 108.635,\n",
       " 314.346,\n",
       " 112.241,\n",
       " 1600.0,\n",
       " 319.889,\n",
       " 118.347,\n",
       " 322.131,\n",
       " 323.135,\n",
       " 324.813,\n",
       " 121.534,\n",
       " 122.14,\n",
       " 328.106,\n",
       " 330.832,\n",
       " 333.4480000000001,\n",
       " 1700.0,\n",
       " 1709.0,\n",
       " 1721.0,\n",
       " 1722.0,\n",
       " 349.289,\n",
       " 1763.0,\n",
       " 1776.0,\n",
       " 355.977,\n",
       " 355.655,\n",
       " 1790.0,\n",
       " 1800.0,\n",
       " 359.977,\n",
       " 1837.0,\n",
       " 371.323,\n",
       " 374.9380000000001,\n",
       " 374.932,\n",
       " 374.789,\n",
       " 375.025,\n",
       " 375.98800000000006,\n",
       " 377.846,\n",
       " 378.702,\n",
       " 378.256,\n",
       " 378.35,\n",
       " 380.995,\n",
       " 381.052,\n",
       " 381.317,\n",
       " 1923.0,\n",
       " 383.625,\n",
       " 383.0,\n",
       " 383.472,\n",
       " 384.374,\n",
       " 384.145,\n",
       " 1941.0,\n",
       " 387.86,\n",
       " 388.784,\n",
       " 1988.0,\n",
       " 404.62,\n",
       " 404.798,\n",
       " 2045.0,\n",
       " 407.475,\n",
       " 2054.0,\n",
       " 2061.0,\n",
       " 411.755,\n",
       " 2079.0,\n",
       " 414.174,\n",
       " 414.783,\n",
       " 415.36,\n",
       " 415.876,\n",
       " 415.562,\n",
       " 416.249,\n",
       " 417.576,\n",
       " 417.265,\n",
       " 418.889,\n",
       " 418.345,\n",
       " 419.557,\n",
       " 419.577,\n",
       " 419.4380000000001,\n",
       " 420.701,\n",
       " 420.006,\n",
       " 420.74300000000005,\n",
       " 421.323,\n",
       " 423.615,\n",
       " 423.23,\n",
       " 425.095,\n",
       " 425.418,\n",
       " 426.47,\n",
       " 427.341,\n",
       " 427.826,\n",
       " 427.514,\n",
       " 2149.0,\n",
       " 428.423,\n",
       " 428.717,\n",
       " 2158.0,\n",
       " 430.082,\n",
       " 431.727,\n",
       " 432.019,\n",
       " 432.241,\n",
       " 432.256,\n",
       " 433.24,\n",
       " 434.951,\n",
       " 437.341,\n",
       " 438.129,\n",
       " 2208.0,\n",
       " 439.48,\n",
       " 440.75,\n",
       " 444.408,\n",
       " 444.394,\n",
       " 2236.0,\n",
       " 445.298,\n",
       " 445.898,\n",
       " 445.852,\n",
       " 445.538,\n",
       " 446.236,\n",
       " 446.352,\n",
       " 446.98800000000006,\n",
       " 447.174,\n",
       " 447.11,\n",
       " 448.097,\n",
       " 2258.0,\n",
       " 449.909,\n",
       " 449.494,\n",
       " 450.845,\n",
       " 2268.0,\n",
       " 451.828,\n",
       " 451.025,\n",
       " 2276.0,\n",
       " 454.111,\n",
       " 455.975,\n",
       " 455.025,\n",
       " 456.38,\n",
       " 457.376,\n",
       " 457.98800000000006,\n",
       " 457.595,\n",
       " 458.712,\n",
       " 458.102,\n",
       " 2309.0,\n",
       " 459.385,\n",
       " 462.587,\n",
       " 2341.0,\n",
       " 2365.0,\n",
       " 2377.0,\n",
       " 2379.0,\n",
       " 2384.0,\n",
       " 476.384,\n",
       " 476.972,\n",
       " 2409.0,\n",
       " 2413.0,\n",
       " 2431.0,\n",
       " 2447.0,\n",
       " 487.399,\n",
       " ...}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataframe['priceUSD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-b0777c473706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2017-06-28 00:00:00'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'priceUSD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X, y = create_dataset(dataframe[['priceUSD']])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "dataset = dataset[dataframe['Date'] > pd.to_datetime('2017-06-28 00:00:00')]\n",
    "\n",
    "dataset = dataframe[['priceUSD']].values.astype('float32')\n",
    "# X, y = create_dataset(dataframe[['priceUSD']])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(len(train), len(test))\n",
    "\n",
    "look_back = 10\n",
    "trainX, trainY = create_dataset(train, look_back=look_back)\n",
    "testX, testY = create_dataset(test, look_back=look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split into input (X) and output (Y) variables\n",
    "# #X = dataframe.iloc[:,0:length]\n",
    "# #X = X[[\"hashrate\",\"size90var\",\"difficulty14sma\",\"difficulty30sma\",\"difficulty90sma\",\"difficulty3ema\",\"difficulty7ema\"]]\n",
    "# X = dataframe#[['price7wmaUSD', 'difficulty90var']]\n",
    "# y = dataframe['priceUSD']\n",
    "# #X = X.drop(['Date', 'priceUSD'], axis = 1)\n",
    "# X = X.drop(['priceUSD'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.head(3)\n",
    "#X = X.drop(['Date', 'priceUSD'], axis = 1)\n",
    "# #X = dataframe.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=dataframe.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape=X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, train_size=0.8, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimators=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimators.append(['mixmax',MinMaxScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimators.append(['robust',RobustScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale=Pipeline(estimators,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, train_size=0.8, shuffle=True, random_state=7)\n",
    "\n",
    "# X_train=scale.fit_transform(X_train)\n",
    "# X_test=scale.transform(X_test)\n",
    "\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# lof = LocalOutlierFactor()\n",
    "# yhat = lof.fit_predict(X_train)\n",
    "# mask = yhat != -1\n",
    "# X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "\n",
    "# X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))\n",
    "# X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))\n",
    "\n",
    "# y_train=y_train.values\n",
    "\n",
    "# y_train=np.reshape(y_train, (y_train.shape[0],1,1))\n",
    "\n",
    "# y_test=y_test.values\n",
    "\n",
    "# y_test=np.reshape(y_test,(y_test.shape[0],1,1))\n",
    "\n",
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "def sequential_model(initializer='normal', activation='relu', neurons=100, NUM_FEATURES=90):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model = Sequential()\n",
    "    #model.add(tf.keras.layers.Reshape((NUM_FEATURES,1), input_shape=(NUM_FEATURES,)))\n",
    "    model.add(LSTM(neurons, return_sequences=True, activation='relu',input_shape=(1, look_back)))\n",
    "    model.add(T2V(neurons))\n",
    "    \n",
    "    #model.add(LSTM(neurons, activation=activation, input_shape=(NUM_FEATURES,1)))\n",
    "    #model.add(Bidirectional(LSTM(neurons, return_sequences=True, activation='relu')))\n",
    "    #model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "    \n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1, activation=activation))\n",
    "    #model.compile(loss=\"logcosh\", optimizer=adam, metrics=['mae'])\n",
    "#    model.add(Dense(neurons, input_shape=(NUM_FEATURES,), kernel_initializer=initializer, activation=activation))\n",
    "#     model.add(Dense(neurons, activation=activation))\n",
    "#     model.add(Dense(neurons, activation=activation))\n",
    "    #model.add(tf.keras.layers.Reshape((NUM_FEATURES,1), input_shape=(NUM_FEATURES,)))\n",
    "    #model.add(T2V(neurons))\n",
    "    #model.add(LSTM(neurons, activation=activation, input_shape=(NUM_FEATURES,1)))\n",
    "    #model.add(T2V(neurons))\n",
    "#     model.add(Dense(1, activation=activation, kernel_initializer=initializer))\n",
    "#     model.add(T2V(neurons))\n",
    "#     model.add(Dense(1, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(LSTM(neurons, activation=activation))\n",
    "    # Compile model\n",
    "    adam=keras.optimizers.Adam(lr=lr_schedule(100), amsgrad=True)\n",
    "    #sgd=keras.optimizers.SGD(learning_rate=0.08, momentum=0.9, nesterov=False)\n",
    "    model.compile(loss='mae', optimizer=adam, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('ANN_reg_seven_new.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10,verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=KerasRegressor(build_fn=sequential_model, batch_size=64, epochs=100,verbose=1, shuffle=True,\n",
    "                         validation_split=0.1,validation_freq=1,\n",
    "                        use_multiprocessing=True) #callbacks=[mcp_save,earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "WARNING:tensorflow:From /root/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 28737 samples, validate on 3194 samples\n",
      "Epoch 1/100\n",
      "28737/28737 [==============================] - 5s 160us/sample - loss: 0.4060 - mean_absolute_error: 0.4060 - val_loss: 0.2617 - val_mean_absolute_error: 0.2618\n",
      "Epoch 2/100\n",
      "28737/28737 [==============================] - 3s 112us/sample - loss: 0.3928 - mean_absolute_error: 0.3928 - val_loss: 0.2518 - val_mean_absolute_error: 0.2518\n",
      "Epoch 3/100\n",
      "28737/28737 [==============================] - 3s 115us/sample - loss: 0.3918 - mean_absolute_error: 0.3918 - val_loss: 0.2691 - val_mean_absolute_error: 0.2691\n",
      "Epoch 4/100\n",
      "28737/28737 [==============================] - 3s 108us/sample - loss: 0.3919 - mean_absolute_error: 0.3919 - val_loss: 0.2576 - val_mean_absolute_error: 0.2576\n",
      "Epoch 5/100\n",
      "28737/28737 [==============================] - 3s 87us/sample - loss: 0.3924 - mean_absolute_error: 0.3924 - val_loss: 0.2714 - val_mean_absolute_error: 0.2714\n",
      "Epoch 6/100\n",
      "28737/28737 [==============================] - 3s 94us/sample - loss: 0.3894 - mean_absolute_error: 0.3894 - val_loss: 0.2648 - val_mean_absolute_error: 0.2648\n",
      "Epoch 7/100\n",
      "28737/28737 [==============================] - 3s 104us/sample - loss: 0.3919 - mean_absolute_error: 0.3918 - val_loss: 0.2621 - val_mean_absolute_error: 0.2621\n",
      "Epoch 8/100\n",
      "28737/28737 [==============================] - 3s 98us/sample - loss: 0.3925 - mean_absolute_error: 0.3925 - val_loss: 0.2685 - val_mean_absolute_error: 0.2685\n",
      "Epoch 9/100\n",
      "28737/28737 [==============================] - 3s 98us/sample - loss: 0.3928 - mean_absolute_error: 0.3928 - val_loss: 0.2583 - val_mean_absolute_error: 0.2583\n",
      "Epoch 10/100\n",
      "28737/28737 [==============================] - 3s 96us/sample - loss: 0.3933 - mean_absolute_error: 0.3933 - val_loss: 0.2781 - val_mean_absolute_error: 0.2781\n",
      "Epoch 11/100\n",
      "13952/28737 [=============>................] - ETA: 1s - loss: 0.3958 - mean_absolute_error: 0.3958"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-3a2c0f872ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# Callbacks batch_begin.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    241\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3484\u001b[0m     \"\"\"\n\u001b[1;32m   3485\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3486\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3488\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3392\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3394\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3506\u001b[0m         \u001b[0mkth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0;31m# Check if the array contains any nan's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3508\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3509\u001b[0m         \u001b[0mkth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "regressor.fit(trainX,trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15723/15723 [==============================] - 0s 26us/sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.092442444932622"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=regressor.predict(testX)\n",
    "r2_score(testY, y_pred) #training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325/1325 [==============================] - 0s 47us/sample\n"
     ]
    }
   ],
   "source": [
    "y_pred=regressor.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07285933, 0.07285933, 0.07285933, ..., 0.07285933, 0.07285933,\n",
       "       0.07285933], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683/2683 [==============================] - 0s 29us/sample\n",
      "1316/1316 [==============================] - 0s 30us/sample\n"
     ]
    }
   ],
   "source": [
    "trainPredict = regressor.predict(trainX)\n",
    "testPredict = regressor.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = scaler.inverse_transform([trainPredict])\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform([testPredict])\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 977.99 RMSE\n",
      "Test Score: 2747.66 RMSE\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488.38431680298936"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(testPredict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.loc[(dataframe['rpt_key'] == 'btc_usd')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.loc[(dataframe['rpt_key'] == 'btc_usd')]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df['datetime'] = pd.to_datetime(df['datetime_id'])\n",
    "df = df.loc[df['datetime'] > pd.to_datetime('2017-06-28 00:00:00')]\n",
    "df = df[['last']]\n",
    "\n",
    "dataset = df.values\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31942 15734\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "trainX, trainY = create_dataset(train, look_back=look_back)\n",
    "testX, testY = create_dataset(test, look_back=look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 31931]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-61686aaecd76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Score: %.2f RMSE'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Score: %.2f RMSE'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \"\"\"\n\u001b[1;32m    240\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 241\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/nlp/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 31931]"
     ]
    }
   ],
   "source": [
    "import math\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2683 samples\n",
      "Epoch 1/100\n",
      "2683/2683 - 2s - loss: 0.0242\n",
      "Epoch 2/100\n",
      "2683/2683 - 0s - loss: 0.0185\n",
      "Epoch 3/100\n",
      "2683/2683 - 0s - loss: 0.0157\n",
      "Epoch 4/100\n",
      "2683/2683 - 0s - loss: 0.0149\n",
      "Epoch 5/100\n",
      "2683/2683 - 0s - loss: 0.0145\n",
      "Epoch 6/100\n",
      "2683/2683 - 0s - loss: 0.0139\n",
      "Epoch 7/100\n",
      "2683/2683 - 0s - loss: 0.0134\n",
      "Epoch 8/100\n",
      "2683/2683 - 0s - loss: 0.0126\n",
      "Epoch 9/100\n",
      "2683/2683 - 0s - loss: 0.0115\n",
      "Epoch 10/100\n",
      "2683/2683 - 0s - loss: 0.0101\n",
      "Epoch 11/100\n",
      "2683/2683 - 0s - loss: 0.0082\n",
      "Epoch 12/100\n",
      "2683/2683 - 0s - loss: 0.0060\n",
      "Epoch 13/100\n",
      "2683/2683 - 0s - loss: 0.0037\n",
      "Epoch 14/100\n",
      "2683/2683 - 0s - loss: 0.0024\n",
      "Epoch 15/100\n",
      "2683/2683 - 0s - loss: 0.0021\n",
      "Epoch 16/100\n",
      "2683/2683 - 0s - loss: 0.0021\n",
      "Epoch 17/100\n",
      "2683/2683 - 0s - loss: 0.0021\n",
      "Epoch 18/100\n",
      "2683/2683 - 0s - loss: 0.0021\n",
      "Epoch 19/100\n",
      "2683/2683 - 0s - loss: 0.0020\n",
      "Epoch 20/100\n",
      "2683/2683 - 0s - loss: 0.0020\n",
      "Epoch 21/100\n",
      "2683/2683 - 0s - loss: 0.0020\n",
      "Epoch 22/100\n",
      "2683/2683 - 0s - loss: 0.0020\n",
      "Epoch 23/100\n",
      "2683/2683 - 0s - loss: 0.0020\n",
      "Epoch 24/100\n",
      "2683/2683 - 0s - loss: 0.0020\n",
      "Epoch 25/100\n",
      "2683/2683 - 0s - loss: 0.0020\n",
      "Epoch 26/100\n",
      "2683/2683 - 0s - loss: 0.0019\n",
      "Epoch 27/100\n",
      "2683/2683 - 0s - loss: 0.0019\n",
      "Epoch 28/100\n",
      "2683/2683 - 0s - loss: 0.0019\n",
      "Epoch 29/100\n",
      "2683/2683 - 0s - loss: 0.0019\n",
      "Epoch 30/100\n",
      "2683/2683 - 0s - loss: 0.0019\n",
      "Epoch 31/100\n",
      "2683/2683 - 0s - loss: 0.0018\n",
      "Epoch 32/100\n",
      "2683/2683 - 0s - loss: 0.0018\n",
      "Epoch 33/100\n",
      "2683/2683 - 0s - loss: 0.0018\n",
      "Epoch 34/100\n",
      "2683/2683 - 0s - loss: 0.0018\n",
      "Epoch 35/100\n",
      "2683/2683 - 0s - loss: 0.0018\n",
      "Epoch 36/100\n",
      "2683/2683 - 0s - loss: 0.0018\n",
      "Epoch 37/100\n",
      "2683/2683 - 0s - loss: 0.0017\n",
      "Epoch 38/100\n",
      "2683/2683 - 0s - loss: 0.0017\n",
      "Epoch 39/100\n",
      "2683/2683 - 0s - loss: 0.0017\n",
      "Epoch 40/100\n",
      "2683/2683 - 0s - loss: 0.0017\n",
      "Epoch 41/100\n",
      "2683/2683 - 0s - loss: 0.0017\n",
      "Epoch 42/100\n",
      "2683/2683 - 0s - loss: 0.0016\n",
      "Epoch 43/100\n",
      "2683/2683 - 0s - loss: 0.0016\n",
      "Epoch 44/100\n",
      "2683/2683 - 0s - loss: 0.0016\n",
      "Epoch 45/100\n",
      "2683/2683 - 0s - loss: 0.0016\n",
      "Epoch 46/100\n",
      "2683/2683 - 0s - loss: 0.0016\n",
      "Epoch 47/100\n",
      "2683/2683 - 0s - loss: 0.0015\n",
      "Epoch 48/100\n",
      "2683/2683 - 0s - loss: 0.0015\n",
      "Epoch 49/100\n",
      "2683/2683 - 0s - loss: 0.0015\n",
      "Epoch 50/100\n",
      "2683/2683 - 0s - loss: 0.0015\n",
      "Epoch 51/100\n",
      "2683/2683 - 0s - loss: 0.0015\n",
      "Epoch 52/100\n",
      "2683/2683 - 0s - loss: 0.0015\n",
      "Epoch 53/100\n",
      "2683/2683 - 0s - loss: 0.0014\n",
      "Epoch 54/100\n",
      "2683/2683 - 0s - loss: 0.0014\n",
      "Epoch 55/100\n",
      "2683/2683 - 0s - loss: 0.0014\n",
      "Epoch 56/100\n",
      "2683/2683 - 0s - loss: 0.0014\n",
      "Epoch 57/100\n",
      "2683/2683 - 0s - loss: 0.0014\n",
      "Epoch 58/100\n",
      "2683/2683 - 0s - loss: 0.0014\n",
      "Epoch 59/100\n",
      "2683/2683 - 0s - loss: 0.0014\n",
      "Epoch 60/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 61/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 62/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 63/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 64/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 65/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 66/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 67/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 68/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 69/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 70/100\n",
      "2683/2683 - 0s - loss: 0.0013\n",
      "Epoch 71/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 72/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 73/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 74/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 75/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 76/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 77/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 78/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 79/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 80/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 81/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 82/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 83/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 84/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 85/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 86/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 87/100\n",
      "2683/2683 - 0s - loss: 0.0012\n",
      "Epoch 88/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 89/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 90/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 91/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 92/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 93/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 94/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 95/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 96/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 97/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 98/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 99/100\n",
      "2683/2683 - 0s - loss: 0.0011\n",
      "Epoch 100/100\n",
      "2683/2683 - 0s - loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f069f8b1d10>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(T2V(4))\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 224.65 RMSE\n",
      "Test Score: 832.74 RMSE\n"
     ]
    }
   ],
   "source": [
    "look_back = 10\n",
    "trainX, trainY = create_dataset(train, look_back=look_back)\n",
    "testX, testY = create_dataset(test, look_back=look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:, 0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:, 0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
